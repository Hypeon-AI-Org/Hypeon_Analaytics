# =============================================================================
# HypeOn Analytics V1 - Environment example
# Copy to .env and fill in values. Do not commit .env.
# =============================================================================

# ----- GCP / BigQuery (backend, scripts, agents) -----
# BigQuery auth (not used for Gemini; Copilot uses AI Studio API key below).
# Local: use gcloud auth (no key file). Run: gcloud auth application-default login
# Then leave GOOGLE_APPLICATION_CREDENTIALS unset; BigQuery will use ADC.
# Cloud Run / CI: set GOOGLE_APPLICATION_CREDENTIALS to a service account key path, or use workload identity.
# GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account-key.json

# Application DB project (analytics_insights, decision_history, marketing_performance_daily, etc.)
BQ_PROJECT=your-app-gcp-project-id
# Source/input project (Ads + GA4 raw data). Omit or set same as BQ_PROJECT for single-project setup
BQ_SOURCE_PROJECT=your-source-gcp-project-id
ANALYTICS_DATASET=analytics
ADS_DATASET=146568
GA4_DATASET=analytics_444259275
# BigQuery job/dataset region for GA4 and final table (e.g. europe-north2)
# BQ_LOCATION=europe-north2
# Optional: serve insights from local JSON (e.g. after agents wrote to agents/output/insights_latest.json)
# INSIGHTS_JSON_PATH=agents/output/insights_latest.json
# Ads source is in EU; job runs in EU, then staging is copied to BQ_LOCATION
# BQ_LOCATION_ADS=EU
# Dataset in BQ_PROJECT (EU) for Ads staging; created automatically if missing
# STAGING_EU_DATASET=staging_eu

# ----- API (backend) -----
API_KEY=your-api-key-for-x-api-key-header
ENV=dev
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
JWT_SECRET=

# ----- Analytics cache (Option A: Redis; omit for in-memory fallback) -----
# REDIS_URL=redis://localhost:6379/0

# ----- Copilot: Gemini LLM (Google AI Studio; separate from BigQuery auth) -----
# Get key at https://aistudio.google.com/app/apikey . This is not gcloud/ADC.
GEMINI_API_KEY=your-gemini-api-key
# Optional: model name (default gemini-2.0-flash)
# GEMINI_MODEL=gemini-2.0-flash
# Option B: Vertex AI (GCP) instead of AI Studio â€” uses ADC / GOOGLE_APPLICATION_CREDENTIALS
# GOOGLE_GENAI_USE_VERTEXAI=true
# GOOGLE_CLOUD_PROJECT=your-gcp-project
# GOOGLE_CLOUD_LOCATION=us-central1

# ----- Optional: rules config path (default: repo root rules_config.json) -----
# RULES_CONFIG_PATH=./rules_config.json

# ----- Optional: logging -----
# LOG_LEVEL=INFO
# AUDIT_STDOUT=1

# ----- Agents (run_agents.py, executive_summary_agent.py) -----
# ORGANIZATION_ID=default
# WORKSPACE_ID=
# CLIENT_IDS=1
# RUN_DATE=
# INCREMENTAL_DAYS=

# ----- Airflow / Cloud Composer (when running DAGs) -----
# HYPEON_REPO_PATH=/home/airflow/gcs/dags/hypeon-analytics
# PYTHON=python
# REFRESH_CACHE_URL=https://your-api.example.com  # DAG calls this to refresh cache

# =============================================================================
# Frontend (Vite) - use in frontend/.env or frontend/.env.local
# =============================================================================
# VITE_API_BASE=
# VITE_API_KEY=your-api-key-for-x-api-key-header
